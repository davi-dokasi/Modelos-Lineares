---
title: "Prevendo pre√ßos de carros com estat√≠stica"
subtitle: "Semin√°rio de modelos lineares"
author: "Davi, Diogo, Jo√£o, Thiago e Eduardo Garcez"
date: "`r Sys.Date()`"
output: rmdformats::downcute # install.packages('rmdformats')
params:
  run_chunk: true
---

![](images/cars.png)
```{r setup, include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
# knitr::opts_chunk$set(cache   = TRUE)
knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(echo    = FALSE)
```

```{r libs, include = FALSE}

packages <- c("readr",
              "dplyr",
              "tidyr",
              "ggplot2",
              "corrplot",
              "GGally",
              "knitr",
              "png",
              "rmarkdown",
              "pastecs",
              "RColorBrewer",
              "gridExtra",
              "car",
              "corrplot",
              "lmtest",
              "car",
              "ggfortify")

install_if_missing <- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
}

lapply(packages, install_if_missing)
lapply(packages, library, character.only = TRUE)

colors <- brewer.pal(6, "Set2")
```

```{r data, include = FALSE}

price        <- read_csv("auto-market-dataset/price.csv")
depreciation <- read_csv("auto-market-dataset/depreciation.csv")
applications <- read_csv("auto-market-dataset/applications.csv")
primary      <- read_csv("auto-market-dataset/primary_features.csv")
models       <- read_csv("auto-market-dataset/models.csv")
extra        <- read_csv("auto-market-dataset/extra_options.csv")
mans         <- read_csv("auto-market-dataset/mans.csv")

# Juntando as tabelas pelas chaves
data <- price %>%
  inner_join(extra,        by = "app_id")             %>%
  inner_join(depreciation, by = "app_id")             %>%
  inner_join(applications, by = "app_id")             %>%
  inner_join(primary,      by = "app_id")             %>%
  inner_join(mans,         by = c("man_id"   = "id")) %>%
  inner_join(models,       by = c("model_id" = "id")) %>%
  select(-ends_with(".y"))                            %>%
  rename_with(~ sub("\\.x$", "", .), ends_with(".x"))

data <- data %>%
  filter(is_car == TRUE)

data <- data %>%
  select(app_id,
         price,
         car_run_km,
         prod_year,
         engine_volume,
         cylinders,
         airbags,
         abs_break,
         esd,
         el_windows,
         conditioner,
         leather,
         nav_system,
         model_name,
         category,
         man_id,
         man_name, )

# Retirando registros inconsistentes
data_filter <- data %>%
  filter(price         > 1000 &
         car_run_km    > 1000 &
         engine_volume > 0    &
         cylinders     > 0)

# data_filter <- data_filter %>%
#   filter(price != 8388607)
```

# Introdu√ß√£o

O dataset foi escolhido pela plataforma kaggle e trata de observa√ß√µes sobre o **mercado automotivo online da Georgia** üá¨üá™ no ano de **2024**.

![Pa√≠s localizado no c√°ucaso com cerca de 3,7 milh√µes de habitantes.](images/georgia_loc.png){width=75%}

Conforme o *schema* apresentado a seguir o dataset apresenta diversos detalhes sobre as vendas, condi√ß√µes do carro e outros detalhes mais espec√≠ficos.

Para esse trabalho, com o intuito de enfatizar os processos e an√°lises que foram aprendidos na disciplina, tomamos liberdade de manipular o banco fornecido no site e descosiderar vari√°veis n√£o utilizadas no modelo.

![](images/schema.png)

---

Abaixo tamb√©m apresentamos uma tabela com as vari√°veis que escolhemos enfatizar e ser√£o tratadas no modelo linear simulado.

```{r data_head}

# kable(head(data))
paged_table(head(data))
```

# Explorando o banco de dados

Nos moldes que foram aplicados temos **`r nrow(data_filter)`** registros a serem analisados.

## Estat√≠sticas gerais{.tabset}

---

### Quantitativas

Vis√£o geral de vari√°veis quantitativas;
```{r resum_var}

aux <- stat.desc(data_filter)
aux <- aux[c(4, 5, 8, 9, 12), c(2:7)]

kable(aux, digits = 2)
```

### Categorias

Principais categorias de carros;
![](images/categories.png)
```{r rank_cat}

result <- aggregate(
  price ~ category,
  data = data_filter,
  FUN = function(x) c(count = length(x), mean = mean(x)))

result <- data.frame(
  category   = result$category,
  count      = result$price[, "count"],
  mean_price = result$price[, "mean"]
)

result <- result[order(-result$count), ]

kable(head(result),
      row.names = FALSE)
```

### Montadoras

Montadoras com mais registros;
```{r rank_man}

result <- aggregate(
  price ~ man_name,
  data = data_filter,
  FUN = function(x) c(count = length(x), mean = mean(x)))

result <- data.frame(
  man_name   = result$man_name,
  count      = result$price[, "count"],
  mean_price = result$price[, "mean"]
)

result <- result[order(-result$count), ]

kable(head(result, 10),
      row.names = FALSE)
```

## Representa√ß√µes gr√°ficas{.tabset}

---

### Pre√ßo
```{r}

hist(log(data_filter$price),
     breaks = 30,
     col    = colors[1],
     xlab   = "log(pre√ßo)",
     ylab   = "Frequ√™ncia",
     main   = "Histograma de frequ√™ncia do log dos pre√ßos")
```

### Ano de Fabrica√ß√£o
```{r}

hist(data_filter$prod_year,
     breaks = 30,
     col    = colors[3],
     xlab   = "Ano de Fabrica√ß√£o",
     ylab   = "Frequ√™ncia",
     main   = "Histograma de frequ√™ncia do ano de fabrica√ß√£o")
```

### Caracter√≠sticas espec√≠ficas
```{r}

data_factor <- data_filter %>%
  select(esd, el_windows, abs_break, conditioner, nav_system) %>%
  mutate(across(everything(),
                as.factor)) %>%
  pivot_longer(cols      = everything(),
               names_to  = "feature",
               values_to = "presence")

ggplot(data_factor, aes(x = feature, fill = presence)) +
  geom_bar(position = "fill") +
  labs(title = "Propor√ß√£o da presen√ßa de caracter√≠sticas",
       x     = "",
       y     = "",
       fill  = "") +
  scale_fill_manual(values = c(colors[3], colors[6]),
                    labels = c("N√£o Possui", "Possui")) +
  theme_minimal()
```

## Equa√ß√£o do modelo linear

A equa√ß√£o do modelo linear √© dada por:

$$
\text{price} = \beta_0 + \beta_1 \cdot \text{car_run_km} + \beta_2 \cdot \text{prod_year} + \beta_3 \cdot \text{engine_volume} + \beta_4 \cdot \text{cylinders} + \beta_5 \cdot \text{airbags} + \beta_6 \cdot \text{abs_break} + \beta_7 \cdot \text{esd} + \beta_8 \cdot \text{el_windows} + \beta_9 \cdot \text{conditioner} + \beta_10 \cdot \text{leather} + \beta_11 \cdot \text{nav_system}
$$

```{r mult 1}

model_filter <- lm(price ~ car_run_km
                  + prod_year
                  + engine_volume
                  + cylinders
                  + airbags
                  + abs_break
                  + esd
                  + el_windows
                  + conditioner
                  + leather
                  + nav_system, data = data_filter)

summary(model_filter)
```

Apenas algumas vari√°veis apresentaram signific√¢ncia no modelo. Assim, o pr√≥ximo modelo ser√° constru√≠do excluindo as vari√°veis com p-valor maior que 0,05

```{r mult 2}
model_filter <- lm(price ~ car_run_km
                  + prod_year
                  + engine_volume
                  + cylinders
                  + airbags
                  + abs_break
                  + nav_system, data = data_filter)

summary(model_filter)
```

## Interpreta√ß√£o dos Coeficientes

$$
\text{price} = \beta_0 + \beta_1 \cdot \text{car_run_km} + \beta_2 \cdot \text{prod_year} + \beta_3 \cdot \text{engine_volume} + \beta_4 \cdot \text{cylinders} + \beta_5 \cdot \text{airbags} + \beta_6 \cdot \text{abs_break}  + \beta_7 \cdot \text{nav_system}
$$

- $\beta_0$ (intercept) nos indica que o valor esperado quando do ve√≠culo quando todas vari√°veis independentes s√£o iguais a zero. Logo o beta_0 n√£o tem interpreta√ß√£o pr√°tica pois o ano de produ√ß√£o n√£o pode ser 0.

- ***car_run_km*** (Quilometragem): Para cada quil√¥metro adicional rodado, o pre√ßo do ve√≠culo diminu√≠ em m√©dia -0.02 unidades monet√°rias, mantendo todas as outras vari√°veis constantes.

- ***prod_year*** (Ano de produ√ß√£o): Para cada ano adicional de produ√ß√£o, o pre√ßo do ve√≠culo aumenta em m√©dia 634.40 unidades monet√°rias, mantendo todas as outras vari√°veis constantes.

- ***engine_volume*** (volume do motor) : Para cada unidade adicional no volume do motor, o pre√ßo do ve√≠culo aumenta em m√©dia 2.47 unidades monet√°rias, mantendo todas as outras vari√°veis constantes.

- ***cylinders*** (cilindro adicional):  Para cada cilindro adicional, o pre√ßo do ve√≠culo aumenta em m√©dia 1682.0 unidades monet√°rias, mantendo todas as outras vari√°veis constantes.

- ***airbags*** Para cada airbags, o pre√ßo do ve√≠culo diminui em m√©dia -423.1 unidades monet√°rias, mantendo todas as outras vari√°veis constantes.

- ***abs_break*** (Sistema de freio)  Para presen√ßa de ABS, o aumento esperado na vari√°vel resposta √© 1905 unidades monet√°rias, mantendo todas as outras vari√°veis constantes.

- ***nav_system*** (Sistema de navega√ß√£o) Para presen√ßa de Sistema de navega√ß√£o, o aumento esperado na vari√°vel resposta √© 1389 unidades monet√°rias, mantendo todas as outras vari√°veis constantes.

## Interpreta√ß√£o do teste F

**F-statistic**: 248.9 \
**p-valor**: < 2.2e-16 \
**Adjusted R-squared**: 0.03107

- **F-statistic**: O valor de 248.9 indica que a variabilidade explicada pelo modelo √© significativamente maior do que a variabilidade n√£o explicada. Em outras palavras, o modelo como um todo √© significativo.

- **p-valo**r: O p-valor √© extremamente pequeno (< 2.2e-16), o que significa que a probabilidade de observar um valor de F t√£o extremo, ou mais extremo, sob a hip√≥tese nula √© praticamente zero.

- **Adjusted R-squared**: Apenas cerca de 3.1% da variabilidade dos dados observados √© explicada pelo modelo ajustado.

- **Conclus√£o**:
  Apesar do modelo ser estatisticamente significativo como um todo, com um p-valor extremamente pequeno (< 2.2e-16), sua capacidade explicativa √© muito limitada, conforme evidenciado pelo $R^2$ ajustado de apenas 3.1%. Isso indica que o modelo consegue explicar apenas uma pequena fra√ß√£o da variabilidade nos pre√ßos dos carros.

  Portanto, prosseguiremos com a an√°lise detalhada dos res√≠duos, buscando identificar poss√≠veis outliers ou padr√µes que possam estar influenciando negativamente o desempenho do modelo e comprometendo sua capacidade preditiva.

## Voltando a equa√ß√£o...

$$
\text{price} = \beta_0 + \beta_1 \cdot \text{car_run_km} + \beta_2 \cdot \text{prod_year} + \beta_3 \cdot \text{engine_volume} + \beta_4 \cdot \text{cylinders} + \beta_5 \cdot \text{airbags} + \beta_6 \cdot \text{abs_break}  + \beta_7 \cdot \text{nav_system}
$$
Substituindo os valores dos coeficientes estimados, temos:

$$
\begin{align*}
\text{price} = &\ -1,275,000 - 0.02198 \cdot \text{car_run_km} + 634.4 \cdot \text{prod_year} + 2.478 \cdot \text{engine_volume} \\
&+ 1,682 \cdot \text{cylinders} - 423.1 \cdot \text{airbags} + 1,905 \cdot \text{abs_break} + 1,389 \cdot \text{nav_system}
\end{align*}
$$

## Multicolinearidade
Outliers podem distorcer as rela√ß√µes entre vari√°veis, afetando correla√ß√µes e m√©tricas como o VIF, o que pode dar uma falsa impress√£o da gravidade da multicolinearidade. Para minimizar esses efeitos, analisamos a multicolinearidade tanto na escala original quanto na logar√≠tmica, j√° que a transforma√ß√£o logar√≠tmica ajuda a estabilizar a vari√¢ncia e reduzir a influ√™ncia de valores extremos.

### Escala original
```{r multicolinearidade, echo=FALSE}
data_filter <- data_filter %>%
  select(price,
         nav_system,
         car_run_km,
         prod_year,
         cylinders,
         airbags,
         abs_break,
         engine_volume)

corrplot(cor(data_filter), method="number", order="hclust", addrect=2, diag=F)
```

```{r}
vif_values <- vif(model_filter)
kable(vif_values, col.names = c("VIF"))
```

Com base nas correla√ß√µes moderadas entre algumas vari√°veis explicativas e os baixos valores de VIF (entre 1 e 2), evidenciando que a multicolinearidade n√£o √© um problema relevante neste modelo, pois, embora algumas vari√°veis apresentem covari√¢ncia moderadas entre si, elas n√£o est√£o redundantes a ponto de inflacionar a vari√¢ncia dos coeficientes.

### Com escala log
```{r}
data_filter_log <- data_filter %>%
  mutate(across(where(is.numeric), ~ ifelse(. > 0, log(.), .)))

corrplot(cor(data_filter_log, use = "complete.obs"),
         method = "number",
         order = "hclust",
         addrect = 2,
         diag = FALSE)
```

```{r}
model_filter_log <- lm(price ~ nav_system + car_run_km + prod_year + cylinders + airbags + abs_break + engine_volume,
                       data = data_filter_log)

vif_values_log <- vif(model_filter_log)

kable(data.frame(Vari√°veis = names(vif_values_log), VIF = vif_values_log), col.names = c("Vari√°vel", "VIF"))
```

Mesmo ao aplicar a transforma√ß√£o logar√≠tmica, os valores do VIF permaneceram baixos, indicando que a multicolinearidade n√£o √© um problema relevante neste modelo.

## An√°lise de res√≠duos
  
### Identifica√ß√£o de Outliers por an√°lise de res√≠duos padronizados

```{r}
residuos_padronizados <- rstandard(model_filter)
outliers <- which(abs(residuos_padronizados) > 3)
print(outliers)
length(outliers)
```

  - A an√°lise dos res√≠duos padronizados revelou a presen√ßa de 82 outliers, o que evidencia inconsist√™ncias nos dados ou no ajuste do modelo, indicando que ele n√£o captura adequadamente a variabilidade dos dados.

### Gr√°fico de Res√≠duos vs Ajustados

```{r}
autoplot(model_filter, which = 1)
```

  - O gr√°fico de Res√≠duos vs Valores Ajustados apresenta uma distribui√ß√£o heterog√™nea, com maior dispers√£o dos res√≠duos em valores ajustados mais altos, em torno de 25.000, identificando tr√™s outliers principais, sendo um outlier extremo acima de 8 milh√µes de d√≥lares, que pode ser um erro de registro ou representar uma caracter√≠stica excepcional do banco de dados. 
  - Podemos ver que a vari√¢ncia claramente aumenta para valores ajustados extremos, mas n√£o h√° um padr√£o claro de curva ou tend√™ncia nos res√≠duos que sugira forte n√£o linearidade.
  
### Teste de Breusch-Pagan para Heterocedasticidade

```{r}
bp_test <- bptest(model_filter)
print(bp_test)
```

  - Portanto, o p-valor menor que 0,05 indica que h√° evid√™ncias de heterocedasticidade nos res√≠duos do modelo, isto √©, de que a vari√¢ncia dos res√≠duos n√£o √© constante.
  - A heterocedasticidade visual identificada √© confirmada pelo teste de Breusch-Pagan,
que rejeitou a hip√≥tese nula de que os res√≠duos estejam distribu√≠dos uniformemente ao longo do gr√°fico de forma homoced√°stica, com vari√¢ncia constante.
  - Em teoria, os res√≠duos devem ter m√©dia zero, mas, como podemos ver, os res√≠duos n√£o est√£o perfeitamente equilibrados em torno da linha horizontal, em y = 0, o que indica que a rela√ß√£o entre as vari√°veis explicativas e a resposta n√£o foi totalmente capturada pelo modelo, que necessita ter seu ajuste melhorado.
  
### QQ-Plot

```{r}
autoplot(model_filter, which = 2)
```

  - Os res√≠duos mostram desvios significativos nas caudas em rela√ß√£o √† distribui√ß√£o normal, indicando viola√ß√£o da suposi√ß√£o de normalidade, possivelmente relacionada √† presen√ßa de outliers, como os identificados pelos √≠ndices 45123 e 14042 ou √† variabilidade n√£o explicada adequadamente pelo modelo. 
  
### Teste de Durbin-Watson
Teste para verificar autocorrela√ß√£o nos res√≠duos:

```{r}
dw_test <- dwtest(model_filter)
print(dw_test)
```

  - O p-valor significativo sugere uma leve autocorrela√ß√£o positiva, o que vai contra o princ√≠pio de independ√™ncia entre os res√≠duos. No entanto, dado que o DW est√° quase em 2, essa autocorrela√ß√£o pode n√£o ser severa o suficiente para impactar gravemente as infer√™ncias do modelo.
  
### Scale-Location

```{r}
autoplot(model_filter, which = 3)
```

  - O gr√°fico destaca que os valores do desvio padr√£o dos res√≠duos aumentam √† medida que os valores ajustados crescem, confirmando a vari√¢ncia n√£o constante observada. Isso pode ter ocorrido por conta de vari√°veis preditivas que deixamos de considerar.
  
### Pontos Influentes

```{r}
cooks_distance <- cooks.distance(model_filter)
which(cooks_distance > 4 / length(data_filter))
length(which(cooks_distance > 4 / length(data_filter)))

autoplot(model_filter, which = 4)
```

  - Utilizando a Dist√¢ncia de Cook, s√£o destacadas observa√ß√µes com valores superiores a 
4/n, sendo n o n√∫mero de observa√ß√µes do banco filtrado. O ponto 45123 apresentou um valor elevado, indicando que, al√©m de ser um outlier, exerce uma influ√™ncia exagerada no modelo. Esse comportamento pode distorcer as estimativas dos coeficientes de regress√£o e a infer√™ncia.

### Pontos de Alavanca

```{r}
leverage <- hatvalues(model_filter)

n <- nrow(data_filter)
k <- length(coef(model_filter)) - 1
cutoff_leverage <- 2 * (k + 1) / n 

pontos_alavanca <- which(leverage > cutoff_leverage)

hat_valores <- hatvalues(model_filter)
df <- data.frame(
  obs = seq_along(hat_valores),
  hat = hat_valores
)

limite <- 2 * mean(hat_valores)


ggplot(df, aes(x = obs, y = hat)) +
  geom_bar(stat = "identity", fill = "darkcyan", alpha = 0.8) +
  geom_hline(yintercept = limite, color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(
    title = "Valores de Alavancagem (Hat Values)",
    x = "√çndice da Observa√ß√£o",
    y = "Leverage"
  ) +
  ylim(0, 0.0015) +
  annotate("text", x = 44000, y = 0.0013, label = "3226¬†Observa√ß√µes")  

length(pontos_alavanca)
```

  - Sobre os pontos de alavanca, foram identificadas 3226 observa√ß√µes com alta alavancagem, indicando que essas observa√ß√µes t√™m grande influ√™ncia no ajuste do modelo devido √† sua dist√¢ncia da m√©dia das vari√°veis explicativas. Essa quantidade significativa de pontos sugere um impacto relevante na estrutura do modelo e na estimativa dos coeficientes, o que pode alterar a interpreta√ß√£o dos resultados e refor√ßa a necessidade de verificar a adequa√ß√£o do modelo √†s caracter√≠sticas dos dados.
  
```{r}
autoplot(model_filter, which = 5)
```

  - No gr√°fico Res√≠duos vs Leverage, √© poss√≠vel observar que algumas dessas observa√ß√µes, como os pontos destacados, tamb√©m s√£o outliers, sendo que o ponto 45123 se destaca por tamb√©m ser ponto influente. Esses pontos combinam alavancagem elevada e um grande peso nos res√≠duos, impactando a estabilidade do modelo.

## Transforma√ß√£o em log escala

dois modelos lineares foram ajustados com o objetivo de linearizar rela√ß√µes n√£o lineares presentes nos dados e reduzir os efeitos de heterocedasticidade, buscando uma maior precis√£o nas estimativas.

O primeiro modelo foi ajustado utilizando a transforma√ß√£o logar√≠tmica na vari√°vel dependente $log(price)$, enquanto as vari√°veis independentes permaneceram em sua escala original:

```{r modelo log}
model_log <- lm(log(price) ~ car_run_km
                  + prod_year
                  + cylinders
                  + airbags
                  + abs_break
                + nav_system,
                data = data_filter)


summary(model_log)
```

O segundo modelo tamb√©m utilizou a transforma√ß√£o logar√≠tmica na vari√°vel dependente $log(price)$. Contudo, adicionalmente, a transforma√ß√£o logar√≠tmica foi aplicada na vari√°vel independente "quilometragem rodada pelo carro":

```{r modelo2 log}
model_log2 <- lm(log(price) ~ log(car_run_km)
                  + prod_year
                  + cylinders
                  + airbags
                  + abs_break
                + nav_system,
                data = data_filter)


summary(model_log2)
```

- Manuten√ß√£o de Outliers: Nenhum tratamento foi realizado para remover ou ajustar outliers presentes no conjunto de dados. Todas as observa√ß√µes originais foram mantidas no ajuste dos modelos.

## An√°lise de res√≠duos

### Gr√°fico de Res√≠duos vs Ajustados

```{r}
autoplot(model_log2, which = 1)
```
- A curva azul indica que os res√≠duos seguem um padr√£o n√£o aleat√≥rio, formando uma curvatura (no formato de "U").Isso sugere que o modelo pode n√£o estar capturando bem a rela√ß√£o entre as vari√°veis preditoras e a vari√°vel resposta. Um modelo linear pode n√£o ser a melhor escolha

### QQ-Plot

```{r}
autoplot(model_log2, which = 2)
```

- Os res√≠duos mostram desvios significativos nas caudas em rela√ß√£o √† distribui√ß√£o normal. 
  
### Scale-Location

```{r}
autoplot(model_log2, which = 3)
```

- A heterocedasticidade observada indica que os pressupostos de vari√¢ncia constante dos res√≠duos do modelo linear n√£o s√£o atendidos
  
### Teste de Breusch-Pagan para Heterocedasticidade

```{r}
bp_test <- bptest(model_log2)
print(bp_test)
```

- Portanto, o p-valor menor que 0,05 indica que h√° evid√™ncias de heterocedasticidade nos res√≠duos do modelo, isto √©, de que a vari√¢ncia dos res√≠duos n√£o √© constante.
  
## Conclus√£o

- A transforma√ß√£o log n√£o foi suficiente: Apesar de o logaritmo reduzir a escala e estabilizar a vari√¢ncia em muitos casos, ele pode n√£o corrigir completamente a heterocedasticidade ou a n√£o linearidade.

- Pode ser que a rela√ß√£o entre as vari√°veis explicativas (log(car_run_km), prod_year, etc.) e a vari√°vel resposta ainda n√£o seja bem representada por um modelo linear.

- Outliers podem estar influenciando a an√°lise e distorcendo os resultados do modelo.
